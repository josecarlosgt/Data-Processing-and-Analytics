{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5670f7",
   "metadata": {},
   "source": [
    "# Tutorial Exercise: Analyzing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2683031",
   "metadata": {},
   "source": [
    "Text data has become extremely common as the Internet has become a ubiquitous channel of communication. In business, understanding customer feedback often requires understanding text. In many cases if we want to “listen to the customer” we’ll actually have to read what she’s written—in product reviews, customer feedback forms, opinion pieces, and email messages.\n",
    "\n",
    "Dealing with text requires dedicated preprocessing steps. In this exercise, we will apply Python's features for working with data to examine text data.\n",
    "\n",
    "There are several ways for representing text data depending on the data mining goal. The following list contains words extracted from a [news article](https://www.bbc.com/news/science-environment-49086783 ) published at the BBC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "425a078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"global\", \"warming\", \"unparalleled\", \"2,000\", \"years\", \"speed\", \"extent\", \"global\", \"warming\", \"exceeds\", \"similar\", \"event\", \"past\", \"two\", \"millennia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1255e5",
   "metadata": {},
   "source": [
    "## Analyzing text data\n",
    "\n",
    "The goal is to gain a basic understanding of the information contained in the list of words. One way to meet this goal is to calculate the counts or number of times each word appears in the list. Words with higher counts may represent the central idea and inform us about the information communicated in a given body of text.\n",
    "\n",
    "For example, we would like to generate the following data structure:\n",
    "\n",
    "`{'global': 2,\n",
    " 'warming': 2,\n",
    " 'unparalleled': 1,\n",
    " '2,000': 1,\n",
    " 'years': 1,\n",
    " 'speed': 1,\n",
    " 'extent': 1,\n",
    " 'exceeds': 1,\n",
    " 'similar': 1,\n",
    " 'event': 1,\n",
    " 'past': 1,\n",
    " 'two': 1,\n",
    " 'millennia': 1}`\n",
    "\n",
    "In the data structure above, we can see the words 'global' and 'warming' appear twice, indicating the topic in the list of words may be about global warming. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c29619",
   "metadata": {},
   "source": [
    "> Of course, the size of text data have at the moment is very small. A larger body of text would probably reveal more information about its content. This exercise aims to implement a basic set of operations that generate the data structure above that we can apply to a body of text of any size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa25f62d",
   "metadata": {},
   "source": [
    "## Task 1: Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6429c9",
   "metadata": {},
   "source": [
    "Using [] and ranges, display the first five items of the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "856b9e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18428ec",
   "metadata": {},
   "source": [
    "Create a function that receives a list of words and prints each word in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1faa351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_words(words):\n",
    "    \n",
    "    # YOUR SOLUTION\n",
    "    \n",
    "    # Remove the pass statement after you complete your implementation\n",
    "    pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9e27f4",
   "metadata": {},
   "source": [
    "## Task 2: Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80470869",
   "metadata": {},
   "source": [
    "The data in the list of words is already in a form that we can directly use to generate the data structure containing the counts of each word. The challenge is to define the steps to create such a data structure.\n",
    "\n",
    "The data structure is a Python dictionary where the keys are the words in the list, and the values are the counts. The list already contains the keys, so we need to generate the counts by following these steps:\n",
    "\n",
    "1. Create an empty dictionary\n",
    "2. Iterate the list of words\n",
    "3. For each word:\n",
    "    - If the word does not exist in the dictionary, create an entry in the dictionary with value 1\n",
    "    - If the word already exists in the dictionary, increase by one the value corresponding to the word in the dictionary \n",
    "4. After the iteration, the dictionary should contain a data structure that will allow us to examine the frequency of each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "06bafad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d677dfa",
   "metadata": {},
   "source": [
    "After implementing the steps above, include your implemention in a function called *count_words* that receives a list of words as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc45106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2dd1dd",
   "metadata": {},
   "source": [
    "## Task 3: Data representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f86fb9",
   "metadata": {},
   "source": [
    "So far, we haven't needed to perform any form of preprocessing because the data we used was already in a form that we could use directly to perform our analysis. However, that's seldom the case.\n",
    "\n",
    "Take a look at the text data in the following cell. Text data would seldom be available for us as a Python list. Instead, it would come in long streams of characters like the following string: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "299aa2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Global warming unparalleled in 2,000 years. The speed and extent of global warming exceed any similar event in the past two millennia. They show that famous historical events like the Little Ice Age don't compare with the scale of the last century's warming.\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"Global warming unparalleled in 2,000 years. The speed and extent of global warming exceed any similar event in the past two millennia. They show that famous historical events like the Little Ice Age don't compare with the scale of the last century's warming.\"\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918c188",
   "metadata": {},
   "source": [
    "To analyze this body of text, we need to transform it into an array of words that can pass to the *count_words* function implemented in the analysis phase.\n",
    "\n",
    "Using the [split](https://www.w3schools.com/python/ref_string_split.asp) method, transform the string contained in the *corpus* variable into an array of items where each item represents a word and assign it to a variable called *words_list*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "555cbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION\n",
    "\n",
    "words_list = []\n",
    "print_words(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12e1d2",
   "metadata": {},
   "source": [
    "Use the *count_words* function to rerun your analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f1ea2d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(words_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a299ac",
   "metadata": {},
   "source": [
    "> Note that this time, the analysis is not accurate. The word 'warming' appears as different entries in the dictionary. This issue highlights the need for performing some preprocessing operations to transform the data into a form more amenable to the analysis we want to apply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2940b",
   "metadata": {},
   "source": [
    "## Task 4: Data cleaning - remove punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a253b9",
   "metadata": {},
   "source": [
    "The first preprocessing task consists of removing the period (.) at the end of some words.\n",
    "\n",
    "Write a function a named *clean_punctuation* that receives a list of words as a parameter and returns another list of words where each word has no punctuation marks at the end.\n",
    "\n",
    "Tips:\n",
    "- Use the [strip](https://www.w3schools.com/python/ref_string_strip.asp) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6110cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# YOUR SOLUTION\n",
    "\n",
    "def clean_punctuation(words):\n",
    "    clean_words = []\n",
    "    \n",
    "    return clean_words\n",
    "\n",
    "words = clean_punctuation(words_list)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b14bb",
   "metadata": {},
   "source": [
    "## Task 5: Data transformation - case-normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609ddf3",
   "metadata": {},
   "source": [
    "The second preprocessing tasks consists on representing all characters in the text body using the same font case, an operation known as case-normalization.\n",
    "\n",
    "Write a function a named *normalize* that receives a list of words as a parameter and returns another list of words where each word is in lower case:\n",
    "\n",
    "Tips:\n",
    "- Use the [lower](https://www.w3schools.com/python/ref_string_lower.asp) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a63c81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SOLUTION\n",
    "\n",
    "def normalize(words):\n",
    "    normalized_words = []\n",
    "    \n",
    "    return normalized_words\n",
    "\n",
    "words = normalize(words)\n",
    "print_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69983e2",
   "metadata": {},
   "source": [
    "Now, call the *count_words* function again after performing the preprocessing operations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d11f0284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f4c24",
   "metadata": {},
   "source": [
    "## Task 6: Data analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc8dcd",
   "metadata": {},
   "source": [
    "To make the preprocessing of data more efficient and flexible, we can construct a pipeline that operationalizes the application of each preprocessing task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1b99a0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [normalize, clean_punctuation]\n",
    "\n",
    "for task in pipeline:\n",
    "    words = task(words_list)\n",
    "\n",
    "count_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cc06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
